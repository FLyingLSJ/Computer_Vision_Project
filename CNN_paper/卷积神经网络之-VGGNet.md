# 卷积神经网络之-VGGNet

VGGNet 是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，他们以7.32%的错误率赢得了2014年ILSVRC分类任务的亚军（冠军由GoogLeNet以6.65%的错误率夺得）和25.32%的错误率夺得定位任务（Localization）的第一名（GoogLeNet错误率为26.44%）

论文地址：[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)

### 网络结构

在《Very Deep Convolutional Networks for Large-Scale Image Recognition》论文中，作者给出了 6 个 VGG 模型，对应不同的网络结构和深度，具体结构如下：

![不同的网络结构](https://cdn.nlark.com/yuque/0/2019/png/653487/1577264283355-7035c69b-53af-46ee-ba8a-371461502c4e.png)



![不同网络结构的参数量（单位：百万）](https://cdn.nlark.com/yuque/0/2019/png/653487/1577263712606-de304fe7-b622-4617-901d-6b57efc34ad2.png)





![VGG-19 的网络结构](https://cdn.nlark.com/yuque/0/2019/jpeg/653487/1577280039174-8b8d55a5-b7e7-4a53-bbc3-b5b0202b00cf.jpeg)
### 设计要点

- 预处理过程：图片每个像素中减去在训练集上的图片计算 RGB 均值
- 所有隐藏层都配备了 ReLU 激活
- 全局使用 3×3 小卷积，可以有效的减少参数，2 个 3×3 卷积可以替代一个 5×5 卷积，参数量变成 5×5 卷积的2×3×3/5×5=0.72 倍，3 个  3×3 卷积可以替换 1 个 7×7 卷积，参数量是 7×7 卷积的 3×3×3/7×7=0.6 倍。这样的连接方式使得网络参数量更小，而且多层的激活函数令网络对特征的学习能力更强。多个 3*3 的卷积核比一个较大尺寸的卷积核有更多层的非线性函数，增加了非线性表达，使判决函数更具有判决性。
- 结合 1×1 卷积层是增加决策函数非线性而不影响卷积层感受野的一种方式。
- 训练设置：批量大小设为 256，动量为 0.9。训练通过权重衰减（L2 惩罚乘子设定为 5×10^−4）进行正则化，前两个全连接层采取 dropout 正则化（dropout 比率设定为 0.5）。学习率初始设定为 10−2，然后当验证集准确率停止改善时，学习率以 10 倍的比率进行减小。学习率总共降低 3 次，学习在 37 万次迭代后停止（74 个 epochs）。
- 为了进一步增强训练集，裁剪图像经过了随机水平翻转和随机 RGB 颜色偏移
- 全连接转卷积（测试阶段），使用不同的尺度进行测试

![](https://cdn.nlark.com/yuque/0/2019/jpeg/653487/1577279940621-125c4ab2-59f5-4b1a-8ee9-5ac1e8b6a525.jpeg)


### 结果分析

- 单尺度的测试结果

![image.png](https://cdn.nlark.com/yuque/0/2019/png/653487/1577274792666-8ad6f36c-17be-4266-863f-12ce1af05c23.png)

1. 网络的性能随着网络的加深而提高。
1. 应该注意到 B，C，D 这个网络的性能。C 网络好于 B 网络，说明额外添加的非线性激活函数，确实是有好处的；但是，D 网络好于 C 网络，这说明也可以使用非平凡的感受野（ non-trivial receptive fields）来捕获更多的信息更有用。
1. 当网络层数达到 19 层时，使用 VGG 架构的错误率就不再随着层数加深而提高了。更深的网络应该需要更多的数据集。
1. 论文还将网络 B 与具有 5×5 卷积层的浅层网络进行了比较，浅层网络可以通过用单个 5×5 卷积层替换 B 中每对 3×3 卷积层得到。测量的浅层网络 top-1 错误率比网络 B 的 top-1 错误率（在中心裁剪图像上）高 7％，这证实了具**有小滤波器的深层网络优于具有较大滤波器的浅层网络。**




- 多尺度评估，测试图像的尺度抖动对性能的影响

![](https://cdn.nlark.com/yuque/0/2019/png/653487/1577276954374-631f46e4-c3c4-4aea-ae72-0d26a67f5740.png)

在单尺度上评估 ConvNet 模型后，我们现在评估测试时尺度抖动的影响。它包括在一张测试图像的几个归一化版本上运行模型（对应于不同的 Q 值），然后对所得到的类别后进行平均。考虑到训练和测试尺度之间的巨大差异会导致性能下降，用固定 S 训练的模型在三个测试图像尺度上进行了评估，接近于训练的尺度：Q = ｛S−32, S, S+32｝。同时，训练时的尺度抖动允许网络在测试时应用于更广的尺度范围，所以用变量 S ∈ [Smin;  Smax] 训练的模型在更大的尺寸范围 Q = {Smin, 0.5(Smin + Smax), Smax} 上进行评估。

- 稠密和多裁剪图像评估

Dense（密集评估），即指全连接层替换为卷积层（第一 FC 层转换到 7×7 卷积层，最后两个 FC 层转换到 1×1 卷积层），最后得出一个预测的 score map，再对结果求平均。

multi-crop，即对图像进行多样本的随机裁剪，将得到多张裁剪得到的图像输入到网络中，最终对所有结果平均

![](https://cdn.nlark.com/yuque/0/2019/png/653487/1577279150113-3c1bcbfa-e50b-4e24-82d2-31573463f754.png)

### 模型特性

- 整个网络都使用卷积核尺寸为 3×3 和最大池化尺寸2×2。
- VGGNet 在训练时有一个小技巧，先训练浅层的的简单网络 VGG11，再复用 VGG11 的权重来初始化 VGG13，如此反复训练并初始化 VGG19，能够使训练时收敛的速度更快。
- 在训练过程中使用多尺度的变换对原始数据做数据增强，使得模型不易过拟合。



参考：

- [https://www.bbsmax.com/A/o75Nv7M95W/](https://www.bbsmax.com/A/o75Nv7M95W/)

![](https://cdn.nlark.com/yuque/0/2020/png/653487/1577876323554-bb5737ae-3b9c-4619-a9f1-f6a33e4d6a00.png)




