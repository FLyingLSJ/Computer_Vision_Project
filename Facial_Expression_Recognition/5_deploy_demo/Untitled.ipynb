{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T04:36:59.829198Z",
     "start_time": "2019-08-29T04:36:09.879888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 49, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 48])\n",
      "torch.Size([1, 3, 48, 156])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1200]' is invalid for input of size 4320",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3470644e1a81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mimgblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             cv2.putText(frame, \n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\jupyter\\Pytorch\\computer_vision\\projects\\classification\\pytorch\\motion_project\\deploy_demo\\net.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 1200]' is invalid for input of size 4320"
     ]
    }
   ],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@author:asus_pc\n",
    "@file: face_detector.py\n",
    "@time: 2019/08/17\n",
    "\"\"\"\n",
    "\n",
    "# 开发环境\n",
    "# Python3.6\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from net import simpleconv3\n",
    "import cv2  # 4.0.0\n",
    "import dlib  # 19.8.1 到 https://pypi.org/simple/dlib/ 下载 whl 文件 pip install *.whl 安装\n",
    "import numpy as np  # 1.16.2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 配置 Dlib 关键点检测路径\n",
    "# 文件可以从 http://dlib.net/files/ 下载\n",
    "PREDICTOR_PATH = \"F:/jupyter/Pytorch/computer_vision/projects/classification/pytorch/motion_project/face_detection/shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)  # 关键点检测\n",
    "# 配置人脸检测器路径\n",
    "cascade_path = \"F:/jupyter/Pytorch/computer_vision/projects/classification/pytorch/motion_project/face_detection/haarcascade_frontalface_default.xml\"  # 在 opencv github 可以找到\n",
    "# 初始化分类器\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "\n",
    "# 调用 cascade.detectMultiScale 人脸检测器和 Dlib 的关键点检测算法 predictor 获得关键点结果\n",
    "def get_landmarks(im):\n",
    "    try:\n",
    "        rects = cascade.detectMultiScale(im, 1.3, 5)  # 进行多尺度检测\n",
    "        if len(rects) == 1:\n",
    "            x, y, w, h = rects[0]\n",
    "            rect = dlib.rectangle(int(x), int(y), int(x + w),\n",
    "                                  int(y + h))  # 获得检测框\n",
    "            # 调用 dlib 关键点检测\n",
    "            return np.matrix([[p.x, p.y] for p in predictor(im, rect).parts()])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "#  打印关键点信息方便调试\n",
    "def annotat_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im,\n",
    "                    str(idx),\n",
    "                    pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 5, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "\n",
    "def get_mouth(im):\n",
    "    # 得到 68 个关键点\n",
    "    landmarks = get_landmarks(im)\n",
    "    if landmarks is not None:\n",
    "        # print(landmarks)\n",
    "        xmin = 10000\n",
    "        xmax = 0\n",
    "        ymin = 10000\n",
    "        ymax = 0\n",
    "        # 根据最外围的关键点获取包围嘴唇的最小矩形框\n",
    "        # 68 个关键点是从\n",
    "        # 左耳朵0 -下巴-右耳朵16-左眉毛（17-21）-右眉毛（22-26）-左眼睛（36-41）\n",
    "        # 右眼睛（42-47）-鼻子从上到下（27-30）-鼻孔（31-35）\n",
    "        # 嘴巴外轮廓（48-59）嘴巴内轮廓（60-67）\n",
    "        for i in range(48, 67):\n",
    "            x = landmarks[i, 0]\n",
    "            y = landmarks[i, 1]\n",
    "            if x < xmin:\n",
    "                xmin = x\n",
    "            if x > xmax:\n",
    "                xmax = x\n",
    "            if y < ymin:\n",
    "                ymin = y\n",
    "            if y > ymax:\n",
    "                ymax = y\n",
    "        # print(\"xmin\", xmin)\n",
    "        # print(\"xmax\", xmax)\n",
    "        # print(\"ymin\", ymin)\n",
    "        # print(\"ymax\", ymax)\n",
    "        roiwidth = xmax - xmin  # 矩形框的宽和高\n",
    "        roiheight = ymax - ymin\n",
    "        roi = im[ymin:ymax, xmin:xmax, :]\n",
    "        # cv2.imshow(\"roi_0\", roi)\n",
    "        # 将最小矩形扩大 1.5 倍，获得最终矩形框\n",
    "        if roiwidth > roiheight:  # 宽和高哪个大哪个就 ×1.5 倍\n",
    "            dstlen = 1.5 * roiwidth\n",
    "        else:\n",
    "            dstlen = 1.5 * roiheight\n",
    "\n",
    "        diff_xlen = dstlen - roiwidth\n",
    "        diff_ylen = dstlen - roiheight\n",
    "        newx = xmin\n",
    "        newy = ymin\n",
    "        imagerows, imagecols, ch = im.shape\n",
    "        # print(\"imagerows, imagecols\", imagerows, imagecols)\n",
    "        if newx >= diff_xlen / 2 and newx + roiwidth + diff_xlen / 2 < imagecols:\n",
    "            newx = newx - diff_xlen / 2\n",
    "        elif newx < diff_xlen / 2:\n",
    "            newx = 0\n",
    "        else:\n",
    "            newx = imagecols - dstlen\n",
    "\n",
    "        if newy >= diff_ylen / 2 and newy + roiheight + diff_ylen / 2 < imagerows:\n",
    "            newy = newy - diff_ylen / 2\n",
    "        elif newy < diff_ylen / 2:\n",
    "            newy = 0\n",
    "        else:\n",
    "            newy = imagecols - dstlen\n",
    "\n",
    "        roi = im[int(newy):int(newy + dstlen), int(newx):int(newx + dstlen), :]\n",
    "        return roi  # 得到人脸关键点就返回嘴巴区域\n",
    "\n",
    "    return None  # 否则返回空\n",
    "\n",
    "\n",
    "#         cv2.imshow(\"roi\", roi)\n",
    "#         cv2.imwrite(dst+im_path.name, roi)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建一个 VideoCapture 对象，参数是设备的索引即摄像机的编号或者 Video 的文件名\n",
    "    # 这里的 0 是指第一台摄像机，以此类推\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(48),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    net = simpleconv3()\n",
    "    modelpath = \"./models/model.ckpt\"\n",
    "    net.load_state_dict(\n",
    "        torch.load(modelpath, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    result_dict = {0: \"no-smile\", 1: \"pout\", 2: \"smile\"}\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    while (ret):\n",
    "        # while cap.isOpened():\n",
    "        # 一帧一帧的捕获\n",
    "        ret, frame = cap.read()\n",
    "        roi = get_mouth(frame)\n",
    "        if roi is not None:\n",
    "            roi_pil = Image.fromarray(roi)\n",
    "            imgblob = data_transforms(roi_pil).unsqueeze(0)\n",
    "            print((imgblob.shape))  # [1, 3, 48, 48]\n",
    "            imgblob = Variable(imgblob)\n",
    "            torch.no_grad()\n",
    "            predict = F.softmax(net(imgblob), dim=1)\n",
    "            result = predict.argmax().item()\n",
    "            cv2.putText(frame, \n",
    "                        result_dict[result], \n",
    "                        (50, 50),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                        fontScale=1,\n",
    "                        color=(0, 0, 255),\n",
    "                       thickness=2)\n",
    "\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T05:12:54.553590Z",
     "start_time": "2019-08-29T05:12:48.493504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "#!usr/bin/env python\n",
    "# -*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@author:asus_pc\n",
    "@file: face_detector.py\n",
    "@time: 2019/08/17\n",
    "\"\"\"\n",
    "\n",
    "# 开发环境\n",
    "# Python3.6\n",
    "\n",
    "# Python 2/3 compatibility\n",
    "from __future__ import print_function\n",
    "import cv2  # 4.0.0\n",
    "import dlib  # 19.8.1 到 https://pypi.org/simple/dlib/ 下载 whl 文件 pip install *.whl 安装\n",
    "import numpy as np  # 1.16.2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from net import simpleconv3\n",
    "\n",
    "\n",
    "\n",
    "# 配置 Dlib 关键点检测路径\n",
    "# 文件可以从 http://dlib.net/files/ 下载\n",
    "PREDICTOR_PATH = \"F:/jupyter/Pytorch/computer_vision/projects/classification/pytorch/motion_project/face_detection/shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)  # 关键点检测\n",
    "# 配置人脸检测器路径\n",
    "cascade_path = \"F:/jupyter/Pytorch/computer_vision/projects/classification/pytorch/motion_project/face_detection/haarcascade_frontalface_default.xml\"  # 在 opencv github 可以找到\n",
    "# 初始化分类器\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "\n",
    "# 调用 cascade.detectMultiScale 人脸检测器和 Dlib 的关键点检测算法 predictor 获得关键点结果\n",
    "def get_landmarks(im):\n",
    "    try:\n",
    "        rects = cascade.detectMultiScale(im, 1.3, 5)  # 进行多尺度检测\n",
    "        if len(rects) == 1:\n",
    "            x, y, w, h = rects[0]\n",
    "            rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))  # 获得检测框\n",
    "            return np.matrix([[p.x, p.y] for p in predictor(im, rect).parts()])  # 调用 dlib 关键点检测\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "#  打印关键点信息方便调试\n",
    "def annotat_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx),\n",
    "                    pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 5, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "\n",
    "def get_mouth(im):\n",
    "    # 得到 68 个关键点\n",
    "    landmarks = get_landmarks(im)\n",
    "    if landmarks is not None:\n",
    "        # print(landmarks)\n",
    "        xmin = 10000\n",
    "        xmax = 0\n",
    "        ymin = 10000\n",
    "        ymax = 0\n",
    "        # 根据最外围的关键点获取包围嘴唇的最小矩形框\n",
    "        # 68 个关键点是从\n",
    "        # 左耳朵0 -下巴-右耳朵16-左眉毛（17-21）-右眉毛（22-26）-左眼睛（36-41）\n",
    "        # 右眼睛（42-47）-鼻子从上到下（27-30）-鼻孔（31-35）\n",
    "        # 嘴巴外轮廓（48-59）嘴巴内轮廓（60-67）\n",
    "        for i in range(48, 67):\n",
    "            x = landmarks[i, 0]\n",
    "            y = landmarks[i, 1]\n",
    "            if x < xmin:\n",
    "                xmin = x\n",
    "            if x > xmax:\n",
    "                xmax = x\n",
    "            if y < ymin:\n",
    "                ymin = y\n",
    "            if y > ymax:\n",
    "                ymax = y\n",
    "        # print(\"xmin\", xmin)\n",
    "        # print(\"xmax\", xmax)\n",
    "        # print(\"ymin\", ymin)\n",
    "        # print(\"ymax\", ymax)\n",
    "        roiwidth = xmax - xmin  # 矩形框的宽和高\n",
    "        roiheight = ymax - ymin\n",
    "        roi = im[ymin:ymax, xmin:xmax, :]\n",
    "        # cv2.imshow(\"roi_0\", roi)\n",
    "        # 将最小矩形扩大 1.5 倍，获得最终矩形框\n",
    "        if roiwidth > roiheight:  # 宽和高哪个大哪个就 ×1.5 倍\n",
    "            dstlen = 1.5 * roiwidth\n",
    "        else:\n",
    "            dstlen = 1.5 * roiheight\n",
    "\n",
    "        diff_xlen = dstlen - roiwidth\n",
    "        diff_ylen = dstlen - roiheight\n",
    "        newx = xmin\n",
    "        newy = ymin\n",
    "        imagerows, imagecols, ch = im.shape\n",
    "        # print(\"imagerows, imagecols\", imagerows, imagecols)\n",
    "        if newx >= diff_xlen / 2 and newx + roiwidth + diff_xlen / 2 < imagecols:\n",
    "            newx = newx - diff_xlen / 2\n",
    "        elif newx < diff_xlen / 2:\n",
    "            newx = 0\n",
    "        else:\n",
    "            newx = imagecols - dstlen\n",
    "        if newy >= diff_ylen / 2 and newy + roiheight + diff_ylen / 2 < imagerows:\n",
    "            newy = newy - diff_ylen / 2\n",
    "        elif newy < diff_ylen / 2:\n",
    "            newy = 0\n",
    "        else:\n",
    "            newy = imagecols - dstlen\n",
    "\n",
    "        roi = im[int(newy):int(newy + dstlen), int(newx):int(newx + dstlen), :]\n",
    "        return roi\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建一个 VideoCapture 对象，参数是设备的索引即摄像机的编号或者 Video 的文件名\n",
    "    # 这里的 0 是指第一台摄像机，以此类推\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(48),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    net = simpleconv3()\n",
    "    modelpath = \"./models/model.ckpt\"\n",
    "    net.load_state_dict(\n",
    "        torch.load(modelpath, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    result_dict = {0: \"no-smile\", 1: \"pout\", 2: \"smile\"}\n",
    "    \n",
    "    img_path = \"pout2.jpg\"\n",
    "    im = cv2.imread(img_path)\n",
    "    roi = get_mouth(im)\n",
    "    if roi is not None:\n",
    "        roi_pil = Image.fromarray(roi)\n",
    "        imgblob = data_transforms(roi_pil).unsqueeze(0)\n",
    "        print(imgblob.shape) # [1, 3, 48, 48]\n",
    "        imgblob = Variable(imgblob)\n",
    "        torch.no_grad()\n",
    "        predict = F.softmax(net(imgblob), dim=1)\n",
    "        result = predict.argmax().item()\n",
    "#         print(predict.argmax().item())\n",
    "        cv2.putText(im, \n",
    "                    result_dict[result], \n",
    "                    (50, 50), \n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=2,\n",
    "                    color=(0, 0, 255),\n",
    "                   thickness=2)\n",
    "    cv2.imshow(\"result\", im)\n",
    "    \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
