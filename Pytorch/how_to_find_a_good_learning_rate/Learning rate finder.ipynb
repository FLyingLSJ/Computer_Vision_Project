{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:25:59.700462Z",
     "start_time": "2019-10-28T07:25:59.687469Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#pytorch packages\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "#To download the dataset for torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will try to recognize hand-written digits, specifically the ones of the MNIST dataset, that contains overall 70,000 28-by-28-pixels pictures of hand-written digits. This dataset is easily accessible in pytorch via dataset.MNSIT. You just have to specify you want to download it if it's not already in the directory, and pytorch will process it to create a DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:01.009714Z",
     "start_time": "2019-10-28T07:26:01.004715Z"
    }
   },
   "outputs": [],
   "source": [
    "#Change to the directory of your choice.\n",
    "PATH = './Mnist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:27.401615Z",
     "start_time": "2019-10-28T07:26:25.279828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./Mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting ./Mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./Mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./Mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./Mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./Mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./Mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./Mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trn_set = datasets.MNIST(PATH, train=True, download=True)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data in the training set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:28.565950Z",
     "start_time": "2019-10-28T07:26:28.556954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set.data), len(tst_set.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented by a tensor of size 28 by 28, each value represents the color of the corresponding pixel, from 0 (black) to 255 (white). Torch tensors are the equivalent of numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:36.482420Z",
     "start_time": "2019-10-28T07:26:36.457434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to convert a torch tensor to a numpy array via the .numpy() command.\n",
    "\n",
    "Conversely, you can create a torch Tensor from a numpy array x via torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:42.997694Z",
     "start_time": "2019-10-28T07:26:42.984701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.data[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then easy to see the corresponding picture via plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:50.548374Z",
     "start_time": "2019-10-28T07:26:50.173588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x215d6b22e80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trn_set.data[0].numpy(), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the corresponding label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:26:59.990971Z",
     "start_time": "2019-10-28T07:26:59.982975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pytorch neural network will expect the data to come in the form of minibatches of tensors. To do that, we use a pytorch object called DataLoader. It will randomly separate the pictures (with the associated label) in minibatches. If you have multiple GPUs, it also prepares the work to be parallelized between them (just change num_workers from 0 to your custom value). We only shuffle the data randomly for the training.\n",
    "\n",
    "First we need to explicitely ask our dataset to transform the images in tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:04.607331Z",
     "start_time": "2019-10-28T07:27:04.551363Z"
    }
   },
   "outputs": [],
   "source": [
    "tsfms = transforms.ToTensor()\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:05.262957Z",
     "start_time": "2019-10-28T07:27:05.240968Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example. A data loader can be converted into an iterator and we can then ask him for a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:06.978976Z",
     "start_time": "2019-10-28T07:27:06.617181Z"
    }
   },
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a minibacth containts two torch tensors: the first one contains the data (here our pictures) and the second one the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:07.912441Z",
     "start_time": "2019-10-28T07:27:07.903446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0].size(), mb_example[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch has automatically added one dimension to our images (the 1 in second position). It would be 3 if we had had the three usual channels for the colors (RGB). Pytorch puts this channel in the second dimension and not the last because it simplifies some computation.\n",
    "\n",
    "Let's see the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:09.106757Z",
     "start_time": "2019-10-28T07:27:08.961840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.9529, 0.9451, 0.9451, 0.9451, 0.7490, 0.4392, 0.4392,\n",
       "         0.4392, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.9961, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.9725, 0.9216, 0.9216, 0.9216, 0.5647, 0.4118, 0.4118, 0.4118,\n",
       "         0.4118, 0.4118, 0.1882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0980, 0.3647, 0.5843, 0.7686, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9255, 0.3882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.1255, 0.1255, 0.1255,\n",
       "         0.5451, 0.6353, 0.6353, 0.6353, 0.7098, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.1490, 0.1490, 0.1490, 0.1490,\n",
       "         0.2157, 0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2392, 0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275,\n",
       "         0.9098, 0.9922, 0.8392, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.9059,\n",
       "         0.9922, 0.9804, 0.3412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.9020, 0.9922,\n",
       "         0.9765, 0.4627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.7569, 0.9922, 0.9725,\n",
       "         0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6902, 0.9922, 0.9686, 0.4706,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2196, 0.8941, 0.9686, 0.4706, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.9922, 0.8392, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.9922, 0.8549, 0.1059, 0.1059,\n",
       "         0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 0.9294, 0.9922, 0.9843, 0.8627,\n",
       "         0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.4314, 0.3765, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch transformed the values that went from 0 to 255 into floats that go from 0. to 1.\n",
    "\n",
    "We can have a look at the first pictures and draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:34.787066Z",
     "start_time": "2019-10-28T07:27:34.222389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB4CAYAAADrPanmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADhlJREFUeJzt3XtsVFUeB/DvD4oIrWhVFigEjAtIVYKRxQTIAkZXHto/FExLkaKyPlBAEEET/tlFE8THKo9Q62vlpQjESFBQFERWk0rUahQXECxdILBIQIHyWMSzf7Tn9Ezn1U7nzr3nzveTGH6cuTMcp7e/nHueopQCERG5p5XfFSAiotQwgRMROYoJnIjIUUzgRESOYgInInIUEzgRkaOYwImIHJV1CVxETjb677yILPS7XmEiIstF5KCIHBeRXSLyV7/rFAYi0lZEXhORGhE5ISJVIjLS73qFiYiUiMi/RaRWRPaIyJ/9rlMiOX5XINOUUnk6FpFcAP8FsNq/GoXSXAATlVJnRaQPgC0iUqWU+srvijkuB8A+AEMB/AfAKACrRKSvUmqvnxULAxH5C4B5AIoBbAPQxd8aJZd1CbyRMQAOA/iX3xUJE6XUdvuv9f/9EQATeAsopWoB/M0qek9EqgH0B7DXjzqFzN8BzFFKVdb//YCflWmKrOtCaWQCgKWK+wmknYgsFpFTAHYAOAhgvc9VCh0R6QSgN4Dtya6lxESkNYA/AegoIrtFZL+ILBKRdn7XLRHJ1twlIt0BVAPoqZSq9rs+YVT/SzEQwDAA85RS5/ytUXiISBsAGwDsUUo94Hd9XCciBahrcX8FoAjAOQBrAWxRSs32s26JZHMLvAzAZ0ze3lFKnVdKfQagG4BJftcnLESkFYBlAP4HYLLP1QmL0/V/LlRKHVRKHQHwD9SNMwRWtifwJX5XIkvkoK4PnFpIRATAawA6ARjNp5r0UEodA7AfdeM1zsjKBC4igwB0BWefpJ2I/KF+KlaeiLQWkeEAxgLY7HfdQqIcQCGAIqXU6WQXU7P8E8CU+ns4H8A0AO/5XKeEsrIPXEQqALRXSo33uy5hIyIdAawB0A91DYQaAAuUUq/4WrEQEJEeqJttchbAb9ZLDyilVvhSqRCpH1eYD6AUwBkAqwDMUkqd8bViCWRlAiciCoOs7EIhIgoDJnAiIkcxgRMROYoJnIjIUUzgRESOyvRmVpzykpyk+D5+t8ml+t0C/H6bgveud2J+t2yBExE5igmciMhRTOBERI5iAicichQTOBGRo5jAiYgcxQROROSobD/UmCijTp9u2MJ77ty5AIDa2tqY1w4ePBgAUFhYGPVabm6uibt3757OKlISJ0+eNPG6detMPG7cuKhrn332WQDAjBkzPKkLW+BERI7K9H7gXHGVHFezecf3lZgjRoww8caNG1P+nAsvvNDEEyZMMPGCBQsAAG3atEn5s1sgK+7d0tJSE7/99tsJr+3atSsA4PvvvzdlHTp0SOWf5UpMIqIwYQInInIUBzEpZYcOHYr4EwBWrlwZdd0rrzQch3n06FEAwJAhQ0zZW2+9ZeKCgoK01zNINm3alJbPOXOm4ZjGiooKE1955ZUAgJkzZ6bl36EGU6dOBRC/60t3a9ndV7/9Vnd0qT14nWIXSkxsgRMROYoJnIjIUZyFEjyBHsl/4oknTLx48WIAsecx2/eVSPT/kv36mDFjTPzmm28CAHJyPOnd830WSk1NjYmfeeYZAMDw4cNNWVVVlYmrq6vjfs6KFStMfP78eRP36tULALBz586WV7b5An3vNpV9P69evdrE9957L4DI+9meDVRZWQkA6Ny5syl7+OGHAQCrVq1qabU4C4WIKEzYAg+ewLVi7Jbg6NGjTfzNN98AiGyR6Pj22283ZTt27DDxDz/8ACCyBV5UVGTid955BwDQunXrtNS9Ed9b4Okya9YsEz/33HNRr//++++ZrI4WuHs3FVu3bjXxjTfeaGJ9z9rf/ezZs0180UUXRX2WHmy2W+opYguciChMmMCJiBzFeeCU1NNPP21ie0nwqFGjAAA33XSTKbv++usBAEOHDjVl9pzll156CQDw6KOPmjJ7Q6CzZ88CANq3b5+WuodVvK7PNDyqZxX73tRdgnfeeWfMa7/++msAkZuLtW3bNuHne/3zYAuciMhRvrfA7Y7/ZANXekChpKQk4XV6NRoADBgwoAW1IwDIz883cawpf8nYrZCbb7456vVY0wwpth9//BEA8OKLL8Z8/aGHHspkdZxXXl5u4sceeyzhtdddd53X1Wk2tsCJiBzFBE5E5Cjfu1Ds0y2SPUqvXbs24s947M1kLrnkkrjXTZ482cT9+vVL+Jmx9O/f38R6398wmj59uontQcxUxDt9huKzV1rqjcHsMruLasqUKZmrmGNOnDhh4rFjxwIANm/eHHXdpZdeauKPPvrI+4q1AFvgRESOYgInInKU70vp7S6UL7/8EkDkY40uA4APPvjAy7o122WXXWbi5cuXA4jcmChFoViObPv5559NXFZWBgD48MMPTdmtt95q4nfffRcAl9Lb7A2ViouLo163u//szbB8EOh7V8/zBiK7Pxv7+OOPTWwvpfcZl9ITEYWJ7y3wZPTKPCDyVIvG7FNJDh48mPAzjxw5AqDp85ibIw2bCAW6FZOMvp/sVre9Be2SJUsARLYav/jiCxN7fBivUy1wPVhvH1p8/PhxAECXLl1M2bZt20zs82B6oO/dadOmmXjhwoVRr+sVxXpDNQDIy8vzvmJNwxY4EVGYMIETETnK93ngydibxSTaOObxxx9v8mfqg0bjLUeOxR5stZfqU2TXlj6B5I033oh5rZ7rP27cOFO2Z88eE/fp08eDGrrj22+/NfGTTz4JoKHbxGbvAR7mNQgttW/fPhPriQZA7M3AdJn9Mxg8eLCHtWs5tsCJiBwV+EHMoNCbCAHAVVddFfe6sA9iHjp0yMT6TMx58+aZMv1005wzMVu1amhH6AHojh07pqnGEQI5iLl9+3YT2wOWevtSe7rq888/DwAYP368KQvQZmCBu3ftJ8GJEyc26T3t2rUzcd++fU18yy23AIj87gsKCkzs8RbIHMQkIgoTJnAiIkcFfhDTTz/99JOJ7RNmNHsu88yZMzNSJ78tW7bMxE899RSA2I/wOTmJby3d1QJEdqfo0390V0GY6cFfe4/1nTt3mlgP2i9dutSUjRw5MkO1c5u+p06dOpXwOru7RJ/OYw/K23Ps9XoFfd8DDadSAQ2nTA0bNsyUed29xRY4EZGjmMCJiBzFWSgx6HnJQ4YMMWX28ny90dKWLVtMWRrniwZuJN9mHwKr96a++uqrTZl+ZLSPn7Jn5uiuE3u+t71Psy63Z2akUaBmoRQVFQEA3n///Zivf/755wCAgQMHpvuf9kpg7l19n+bm5ia87vXXXzex7m6xt++wzx749NNPASTvFrF/niNGjGhijZPiLBQiojDhIGa9X3/91cR6wNJudduDcq+++iqA4K/S8kJLT3/RJ/rYqwvtFk2Atu/0hL2J0oYNG6Je1wNhAA/kzrRJkyZFlT344IMm1hMV9PqHeFauXGniNLbAY2ILnIjIUUzgRESOyupBzN27d5t4xowZJl63bh2AyL2pX375ZRPby509EJiBIC/oQ2Ltk4vsLhQ9oOnRsmTfBzHtbQNi2bhxo4n1/tQtnUscaxDZPhQ5FvtEJP1+u/ssjsDcu3ogslu3bqbs6NGjUdfZazn0d2//3usTogDgnnvuARD/56EPUN+6daspu+aaa5pd9zg4iElEFCZM4EREjsrqLhT9SAQ0HPUFNCxhLi8vN2V33313pqoVmMfQdNm1a5eJ9WGytbW1psyeM66XK3t0tJrvXSj243eyrpGSkhIAqX0X9u+1vZxc73C4d+/ehO+/4oorTKy7texl45r9e4MA3rup7EYYj/5O4/3c9PYP9tFtacQuFCKiMMnKFnh1dTWAyE1nDh8+bGLd8s5gq9sWuFZMKuwNge644w4T64Eie0DMXtHq8dxn31vg8Z76guziiy8GEHtF6Pr16+2/Bu7etTdN6927t4lramqa/Vl6MNfeA3zTpk0m7tmzJ4DkG7mliC1wIqIwYQInInJUVnahlJaWAohc8mrPB62qqsp4nSy+PIbqx8NffvnFlOl5rcnmLtv0lgR2t8knn3wSdd0jjzxi4hdeeKF5lU2d710o586dM7He59veVmDRokVR1+7fvz/hZ+qfEwDk5+cDiBzEtI+nu+uuu6Lef/nllwNoODKsMT2I2qFDh4T1QAC7UGxr1qwxcXFxcbPff8MNNwCIXBNiH7nmMXahEBGFCVvg9QoLC01cWVkZ9R49tRAALrjgAg9r508rRrf8pk6dasrmzJkDIHJaVF5enomPHTsGIHIg57777gMQuTmYTa8utDdy8mjQJxbfW+DNoVcT6kH3eDp16mRi3QL3SaBb4PY9qVvj999/f9R1PXr0MPH8+fNNrLf/9Qlb4EREYcIETkTkqKzsQtFzV8vKykyZvdGNHrTr1auXKbMH4jp37uxl9Xx5DNWrJe39iw8cOAAgcmMje0BTb4hkn2ASix78ARo2CrMH1jLIqS4UBwW6C8Vx7EIhIgoTJnAiIkdlZReKZm/yYy8J1iP5esZEhvn6GGpvMqVnmehuDwD47rvvTFxRUQEAuO2220zZtddeCyByTvGgQYNM7NEmVU3FLhRvsQvFO+xCISIKk6xugQcUWzHeYQvcW7x3vcMWOBFRmDCBExE5igmciMhRTOBERI5iAicichQTOBGRo5jAiYgclel54ERElCZsgRMROYoJnIjIUUzgRESOYgInInIUEzgRkaOYwImIHMUETkTkKCZwIiJHMYETETmKCZyIyFFM4EREjmICJyJyFBM4EZGjmMCJiBzFBE5E5CgmcCIiRzGBExE5igmciMhRTOBERI5iAicichQTOBGRo5jAiYgcxQROROSo/wNoSCrBe6oV8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0].numpy(), cmap='Greys')\n",
    "    sub_plot.set_title(str(mb_example[1][i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another usual transformation we do before feeing the pictures to our neural network is to normalize the input. This means subtracting the mean and dividing by the standard deviation. We can either search for the usual values on Google or compute them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:44.090744Z",
     "start_time": "2019-10-28T07:27:43.643999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1306), tensor(0.3081))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.mean(trn_set.data.type(torch.FloatTensor))/255.\n",
    "std = torch.std(trn_set.data.type(torch.FloatTensor))/255.\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide by 255 to get the means of our data when it's convereted into floats from 0. to 1.\n",
    "\n",
    "Then we go back to creating a transfrom and add the normalization. Note that we use the same mean and std for the test set. Afterward, we reload our datasets, adding this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:47.011074Z",
     "start_time": "2019-10-28T07:27:46.956105Z"
    }
   },
   "outputs": [],
   "source": [
    "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:48.190400Z",
     "start_time": "2019-10-28T07:27:48.171409Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to plot our digits, we will have to denormalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:27:50.339170Z",
     "start_time": "2019-10-28T07:27:50.242225Z"
    }
   },
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:28:07.615287Z",
     "start_time": "2019-10-28T07:28:06.823739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    sub_plot = fig.add_subplot(1,4,i+1)\n",
    "    sub_plot.axis('Off')\n",
    "    plt.imshow(mb_example[0][i,0].numpy() * std.numpy() + mean.numpy(), cmap='Greys', interpolation=None)\n",
    "    sub_plot.set_title(str(mb_example[1][i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to create a model as a subclass of nn.Module. That way, we can use all the features this class provides.\n",
    "\n",
    "We override the init function (but still call the init function of nn.Module) to define our custom layers (here two linear layers) and we have to define the forward function, which explains how to compute the output.\n",
    "\n",
    "The first line of the forward function is to flatten our input, since we saw it has four dimensions: minibatch by channel by height by width. We only keep the minibatch size as our first dimension (x.size(0)) and the -1 is to tell pytorch to determine the right number for the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:28:10.081877Z",
     "start_time": "2019-10-28T07:28:10.069882Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_in, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_out)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.log_softmax(self.linear2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can instanciate the class with our input size (28 * 28), an hidden size of 100 layers and 10 outputs (as many as digits).\n",
    "\n",
    "The optimizer will automatically do the Stochastic Gradient Descent for us (or any of its variant if we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:28:11.485075Z",
     "start_time": "2019-10-28T07:28:11.464085Z"
    }
   },
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to write our training loop. To compute the gradient automatically, pytorch requires us to put the torch tensors with our inputs and labels into Variable objects, that way it'll remember the transformation these go through until we arrive at our loss function. We then call loss.backward() to compute all the gradients (which will then be in the grad field of any variable).\n",
    "\n",
    "The optimizer takes care of the step of our gradient descent in the optimizer.step() function. Since the gradients are accumulated, we have to tell pytorch when to reinitialize them (which the purpose of the optimizer.zero_grad() command at the beginning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:28:23.413250Z",
     "start_time": "2019-10-28T07:28:23.398257Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        for data in trn_loader:\n",
    "            #separate the inputs from the labels\n",
    "            inputs,labels = data\n",
    "            #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Put the gradients back to zero\n",
    "            optimizer.zero_grad()\n",
    "            #Compute the outputs given by our model at this stage.\n",
    "            outputs = net(inputs)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.data * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds)\n",
    "            #Backpropagate the computation of the gradients\n",
    "            loss.backward()\n",
    "            #Do the step of the SGD\n",
    "            optimizer.step()\n",
    "        print(f'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:34:15.539785Z",
     "start_time": "2019-10-28T07:28:24.961363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.5763763785362244  Accuracy: 85\n",
      "Epoch 2:\n",
      "Loss: 0.30564889311790466  Accuracy: 91\n",
      "Epoch 3:\n",
      "Loss: 0.2609802186489105  Accuracy: 92\n",
      "Epoch 4:\n",
      "Loss: 0.23100027441978455  Accuracy: 93\n",
      "Epoch 5:\n",
      "Loss: 0.20724086463451385  Accuracy: 94\n",
      "Epoch 6:\n",
      "Loss: 0.187913179397583  Accuracy: 94\n",
      "Epoch 7:\n",
      "Loss: 0.17132790386676788  Accuracy: 95\n",
      "Epoch 8:\n",
      "Loss: 0.1572159379720688  Accuracy: 95\n",
      "Epoch 9:\n",
      "Loss: 0.14510478079319  Accuracy: 95\n",
      "Epoch 10:\n",
      "Loss: 0.13480710983276367  Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.3% accuracy is good, but that's on the training set and we may be overfitting. Let's try on the test set now to see if we're doing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:34:21.804201Z",
     "start_time": "2019-10-28T07:34:21.784212Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tst_loader:\n",
    "        #separate the inputs from the labels\n",
    "        inputs,labels = data\n",
    "        #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "        #Even if we don't require the gradient here, a nn.Module expects a variable.\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #Compute the outputs given by our model at this stage.\n",
    "        outputs = net(inputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.data * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds)\n",
    "    print(f'Loss: {running_loss/len(tst_set)}  Accuracy: {100.*corrects/len(tst_set)}')\n",
    "    \n",
    "def validate_2():\n",
    "    net.eval()\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tst_loader:\n",
    "        #separate the inputs from the labels\n",
    "        inputs,labels = data\n",
    "        #wrap those into variables to keep track of how they are created and be able to compute their gradient.\n",
    "        #Even if we don't require the gradient here, a nn.Module expects a variable.\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #Compute the outputs given by our model at this stage.\n",
    "        outputs = net(inputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.data * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds)\n",
    "    print(f'Loss: {running_loss/len(tst_set)}  Accuracy: {100.*corrects/len(tst_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:34:28.565334Z",
     "start_time": "2019-10-28T07:34:22.747661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13608039915561676  Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:34:34.225095Z",
     "start_time": "2019-10-28T07:34:28.816190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13608039915561676  Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "validate_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we weren't overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of how this code has been built are all explained in this [blog article](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:35:02.423964Z",
     "start_time": "2019-10-28T07:35:02.404975Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(trn_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in trn_loader:\n",
    "        batch_num += 1\n",
    "        #As before, get the loss for this mini-batch of inputs/outputs\n",
    "        inputs,labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.data\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        #Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    return log_lrs, losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our neural net as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:35:03.885128Z",
     "start_time": "2019-10-28T07:35:03.877134Z"
    }
   },
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the losses versus the logs of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:35:36.883251Z",
     "start_time": "2019-10-28T07:35:05.204374Z"
    }
   },
   "outputs": [],
   "source": [
    "logs,losses = find_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:35:45.009601Z",
     "start_time": "2019-10-28T07:35:44.532875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x215dcf23400>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests the best learning rate is $10^{-1}$ so we can use test this one after defining a new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:36:22.122430Z",
     "start_time": "2019-10-28T07:35:48.705487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.26230382919311523  Accuracy: 92\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already at 92.21% accuracy when the learning rate used before gave us 84.86% in one epoch!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
